# -*- coding: utf-8 -*-
"""b19200_Dsc_A4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ja9VK1MEedtqCpnUYk2SoAVBjTfz8rDm

Name: Tushika Singh Roll No: B19200 Phone Number: 9444854202
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from google.colab import files
uploaded = files.upload()
import io
data = pd.read_csv(io.BytesIO(uploaded['seismic_bumps1_09c5eea3d1da94ae634c056648a090da.csv']))
# Dataset is now stored in a Pandas Dataframe.
# My code may defer a little because I wrote my codes on Google colab.

newdata= data.drop(['nbumps', 'nbumps2', 'nbumps3', 'nbumps4', 'nbumps5', 'nbumps6', 'nbumps7', 'nbumps89'],axis=1) #removes the attribute

#Question 1
print('\nQuestion1')
X_0 = newdata.groupby('class').get_group(0)          #groups of the data based on class
X_label0 = X_0['class']
X_0 = X_0.drop(['class'], axis=1)                     # drops class label

X_1 = newdata.groupby('class').get_group(1)
X_label1 = X_1['class']
X_1 = X_1.drop(['class'], axis=1)                     # drops class label

[X_train0, X_test0, X_label_train0, X_label_test0] =train_test_split(X_0, X_label0, test_size=0.3, random_state=42,shuffle=True) #splits train and test data based on class
[X_train1, X_test1, X_label_train1, X_label_test1] =train_test_split(X_1, X_label1, test_size=0.3, random_state=42,shuffle=True)

X_train = pd.concat([X_train0,X_train1],axis=0)                     
X_test = pd.concat([X_test0,X_test1],axis=0)                        # combines the data of two classes
X_label_train = pd.concat([X_label_train0,X_label_train1],axis=0)   
X_label_test = pd.concat([X_label_test0,X_label_test1],axis=0)      

pd.concat([X_train,X_label_train],axis=1).to_csv('seismic-bumps-train.csv')
pd.concat([X_test,X_label_test],axis=1).to_csv('seismic-bumps-test.csv')      #Made new csv files of train and test data

train= pd.read_csv(r"E:\3rd Sem\DS3\Assignment4\seismic-bumps-train.csv")
test = pd.read_csv(r"E:\3rd Sem\DS3\Assignment4\seismic-bumps-test.csv")

k = [1,3,5]          #Given values of K

print('\na.')

Accuracy = []
for i in k:
    knn = KNeighborsClassifier(n_neighbors = i)
    knn.fit(X_train, X_label_train)
    Prediction = knn.predict(X_test)
    
    Matrix = confusion_matrix(X_label_test, Prediction)
    Accu = accuracy_score(X_label_test, Prediction)
    
    Accuracy.append(Accu) 
    
    print(f'\nConfusion matrix for k={i} is:')
    print(Matrix) 
    print(f'The classification accuracy for k={i} is',round(Accu,4))


print('\nb.')

KNN_accuracy = max(Accuracy)
a = k[Accuracy.index(max(Accuracy))]
print('Value of K for which the accuracy is high is',a)    
    
#Question 2
print('\nQuestion 2')

Normalized_test =(X_test-X_train.min())/(X_train.max()-X_train.min())
Normalized_train =(X_train-X_train.min())/(X_train.max()-X_train.min())

Normalized_train.to_csv('seismic-bumps-train-Normalised.csv')
Normalized_test.to_csv('seismic-bumps-test-Normalised.csv')         #Made new csv files of normalized data

Normalized_train = pd.read_csv(r"E:\3rd Sem\DS3\Assignment4\seismic-bumps-train-Normalised.csv")
Normalized_test = pd.read_csv(r"E:\3rd Sem\DS3\Assignment4\seismic-bumps-test-Normalised.csv")

Normalized_train.drop(Normalized_train.columns[0],axis=1,inplace=True)
Normalized_test.drop(Normalized_test.columns[0],axis=1,inplace=True)

k = [1,3,5]

print('\na.')

Accuracy_norm = []
for i in k:
    knn = KNeighborsClassifier(n_neighbors = i)
    knn.fit(Normalized_train, X_label_train)
    Prediction = knn.predict(Normalized_test)
    
    Matrix = confusion_matrix(X_label_test, Prediction)
    Accu = accuracy_score(X_label_test, Prediction)
    
    Accuracy_norm.append(Accu) 
    
    print(f'\nConfusion matrix for k={i} is:')
    print(Matrix)
    print(f'The classification accuracy for k={i} is',round(Accu,4))
     

print('\nb.')

KNNnorm_accuracy = max(Accuracy_norm)
b = k[Accuracy_norm.index(max(Accuracy_norm))]
print('Value of K for which the accuracy is high is',b)

#Question 3
print('\nQuestion 3')

def likelihood(X , cov):
    #X = (test case - mu) and cov = covariance matrix
    M= X.dot(np.linalg.inv(cov))
    M= M.dot(X.transpose())        #Mahalanobis distance = M
    # d = 1
    px = (np.exp(-M/2))/((2*np.pi*np.linalg.det(cov))**0.5)
    return px                     # likelihood value

X = X_train.copy()
X['class'] = X_label_train.copy()
c0 = X.groupby('class').get_group(0).drop(['class'],axis=1)     # Class 0 of trained data
c1 = X.groupby('class').get_group(1).drop(['class'],axis=1)     # Class 1 of trained data

mean_c0= c0.mean(axis=0).values                     #mean for class0
mean_c1= c1.mean(axis=0).values                     #mean for class1

cov_c0 = c0.cov().values        #Covariance of class 0 and 1
cov_c1 = c1.cov().values

prior_c0 = X_label_train.tolist().count(0)/len(X_label_train)    #prior of class 0
prior_c1 = 1-prior_c0                                            #prior of class 1
 
X0 = X_test.values - mean_c0                 # x - mu for likelihood function
X1 = X_test.values - mean_c1

Prediction = []
for i in range(len(X_test)):
    px_c0 = likelihood(X0[i] , cov_c0)       #likelihood of class = 0
    px_c1 = likelihood(X1[i], cov_c1)        #likelihood of class = 1
    
    p_x = (px_c0*prior_c0) + (px_c1*prior_c1)      #Evidence
    
    posterior_c0 = (px_c0* prior_c0)/p_x           # (likelihood * prior)/ evidence
    posterior_c1 = (px_c1* prior_c1)/p_x
    
    if posterior_c1 > posterior_c0:
        Prediction.append(1)                       #This will determine class
    else:
        Prediction.append(0)

Matrix = confusion_matrix(X_label_test, Prediction)      #Confusion matrix for Bayes classifier
Accuracy_score= accuracy_score(X_label_test, Prediction) #Accuracy for Bayes Classifier
print('Confusion matrix for Bayes Classifier is')
print(Matrix)
print('The classification accuracy for Bayes Classifier is',Accuracy_score)

print("\nQuestion 4")

Chart = [["KNN", KNN_accuracy*100],["KNN on normalized data", KNNnorm_accuracy*100],["Bayes",Accuracy_score*100]]
Best_Result=pd.DataFrame(Chart , index=[1,2,3], columns=['Classifier','Accuracy(%)'])
print(Best_Result)
print(f"\nThe best result is {round(max(KNN_accuracy, KNNnorm_accuracy ,Accuracy_score)*100,4)}%")